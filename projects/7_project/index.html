<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Advanced Machine Learning Techniques with PyTorch | Daniel Agyapong </title> <meta name="author" content="Daniel Agyapong"> <meta name="description" content="Implementing advanced machine learning algorithms."> <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://engineerdanny.github.io/projects/7_project/"> <script src="/assets/js/theme.js?a5ca4084d3b81624bcfa01156dae2b8e"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Daniel</span> Agyapong </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">Daniel Agyapong </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item active"> <a class="nav-link" href="/projects/">projects <span class="sr-only">(current)</span> </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Advanced Machine Learning Techniques with PyTorch</h1> <p class="post-description">Implementing advanced machine learning algorithms.</p> </header> <article> <h2 id="introduction">Introduction</h2> <p>In the rapidly evolving field of machine learning, staying abreast of the latest techniques and tools is crucial for developing effective and efficient models. This project showcases a comprehensive approach to implementing and evaluating advanced machine learning models using a combination of PyTorch, Scikit-Learn, and Plotnine. The primary goals of this project are to:</p> <ol> <li> <strong>Implement Custom Models</strong>: Develop custom machine learning models, including a basic featureless model, and more sophisticated neural networks using PyTorch.</li> <li> <strong>Cross-Validation and Hyperparameter Tuning</strong>: Utilize cross-validation techniques to optimize model performance and fine-tune hyperparameters for the best results.</li> <li> <strong>Data Preprocessing and Feature Scaling</strong>: Prepare datasets with appropriate preprocessing steps, including feature scaling, to ensure model accuracy and robustness.</li> <li> <strong>Comparative Analysis</strong>: Compare the performance of different models using a standardized evaluation framework.</li> <li> <strong>Visualization of Results</strong>: Generate insightful visualizations using Plotnine to interpret the performance and behavior of models across different datasets and configurations.</li> </ol> <p>The project is structured to cover various aspects of machine learning model development and evaluation. We start with data preparation, including loading and scaling datasets. We then define custom classes for models and datasets, enabling seamless integration with PyTorch’s data handling capabilities. The core of the project involves training neural networks with cross-validation to identify the optimal number of epochs for each model.</p> <p>Moreover, we implement a series of experiments to compare traditional machine learning models, like Logistic Regression and K-Nearest Neighbors, with our neural network models. The performance of these models is evaluated across multiple folds of cross-validation, ensuring a robust assessment.</p> <p>Finally, the project leverages Plotnine for creating detailed diagnostic plots and visualizations. These plots help in understanding the training dynamics and the effectiveness of different models, making it easier to draw actionable insights.</p> <p>By the end of this project, you’ll have a solid understanding of how to build, tune, and evaluate advanced machine learning models using a combination of powerful Python libraries.</p> <h2 id="imports">Imports</h2> <p>To begin, we need to import several essential libraries for our machine learning tasks. These include pandas, numpy, plotnine for visualization, PyTorch for deep learning, and several modules from scikit-learn for data processing and modeling.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="n">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="kn">import</span> <span class="n">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="n">plotnine</span> <span class="k">as</span> <span class="n">p9</span>
<span class="kn">import</span> <span class="n">torch</span>
<span class="kn">from</span> <span class="n">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">KFold</span>
<span class="kn">from</span> <span class="n">sklearn.linear_model</span> <span class="kn">import</span> <span class="n">LogisticRegression</span>
<span class="kn">from</span> <span class="n">sklearn.pipeline</span> <span class="kn">import</span> <span class="n">make_pipeline</span>
<span class="kn">from</span> <span class="n">sklearn.preprocessing</span> <span class="kn">import</span> <span class="n">StandardScaler</span>
<span class="kn">from</span> <span class="n">sklearn.model_selection</span> <span class="kn">import</span> <span class="n">GridSearchCV</span>
<span class="kn">from</span> <span class="n">sklearn.neighbors</span> <span class="kn">import</span> <span class="n">KNeighborsClassifier</span>
<span class="kn">from</span> <span class="n">sklearn.metrics</span> <span class="kn">import</span> <span class="n">plot_roc_curve</span>
<span class="kn">import</span> <span class="n">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
</code></pre></div></div> <h2 id="custom-classes">Custom Classes</h2> <h3 id="featureless-model">Featureless Model</h3> <p>The <code class="language-plaintext highlighter-rouge">FeaturelessModel</code> class is a simple model that predicts the majority class in the training data. It is used as a baseline model to compare the performance of more complex models.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">Featureless</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="n">train_labels</span> <span class="o">=</span> <span class="n">y</span>
        <span class="n">train_label_counts</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nc">Series</span><span class="p">(</span><span class="n">train_labels</span><span class="p">).</span><span class="nf">value_counts</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">featureless_pred_label</span> <span class="o">=</span> <span class="n">train_label_counts</span><span class="p">.</span><span class="nf">idxmax</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="n">test_features</span> <span class="o">=</span> <span class="n">X</span>
        <span class="n">test_nrow</span><span class="p">,</span> <span class="n">test_ncol</span> <span class="o">=</span> <span class="n">test_features</span><span class="p">.</span><span class="n">shape</span>
        <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nf">repeat</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">featureless_pred_label</span><span class="p">,</span> <span class="n">test_nrow</span><span class="p">)</span>
</code></pre></div></div> <h3 id="csv-dataset-class-for-pytorch">CSV Dataset Class for PyTorch</h3> <p>This class helps in loading datasets in a format compatible with PyTorch.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">CSV</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="n">Dataset</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">features</span><span class="p">,</span> <span class="n">labels</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">features</span> <span class="o">=</span> <span class="n">features</span>
        <span class="n">self</span><span class="p">.</span><span class="n">labels</span> <span class="o">=</span> <span class="n">labels</span>

    <span class="k">def</span> <span class="nf">__getitem__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">item</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="n">features</span><span class="p">[</span><span class="n">item</span><span class="p">,</span> <span class="p">:],</span> <span class="n">self</span><span class="p">.</span><span class="n">labels</span><span class="p">[</span><span class="n">item</span><span class="p">]</span>

    <span class="k">def</span> <span class="nf">__len__</span><span class="p">(</span><span class="n">self</span><span class="p">):</span>
        <span class="k">return</span> <span class="nf">len</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">labels</span><span class="p">)</span>
</code></pre></div></div> <h3 id="torch-learner-with-cross-validation">Torch Learner with Cross-Validation</h3> <p>This class helps in loading datasets in a format compatible with PyTorch.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">TorchLearnerCV</span><span class="p">():</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">max_epochs</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">step_size</span><span class="p">,</span> <span class="n">units_per_layer</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">max_epochs</span> <span class="o">=</span> <span class="n">max_epochs</span>
        <span class="n">self</span><span class="p">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
        <span class="n">self</span><span class="p">.</span><span class="n">step_size</span> <span class="o">=</span> <span class="n">step_size</span>
        <span class="n">self</span><span class="p">.</span><span class="n">units_per_layer</span> <span class="o">=</span> <span class="n">units_per_layer</span>
        
    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="n">train_features</span> <span class="o">=</span> <span class="n">X</span>
        <span class="n">train_labels</span> <span class="o">=</span> <span class="n">y</span>
        <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">seed</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>
        <span class="n">n_folds</span> <span class="o">=</span> <span class="mi">2</span>
        <span class="n">fold_vec</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="nf">randint</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="n">n_folds</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">train_labels</span><span class="p">.</span><span class="n">size</span><span class="p">)</span>
        <span class="n">is_set_dict</span> <span class="o">=</span> <span class="p">{</span>
            <span class="sh">"</span><span class="s">subtrain</span><span class="sh">"</span><span class="p">:</span> <span class="n">fold_vec</span> <span class="o">!=</span> <span class="p">(</span><span class="n">n_folds</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span>
            <span class="sh">"</span><span class="s">validation</span><span class="sh">"</span><span class="p">:</span> <span class="n">fold_vec</span> <span class="o">==</span> <span class="p">(</span><span class="n">n_folds</span><span class="o">-</span><span class="mi">1</span><span class="p">),</span>
        <span class="p">}</span>
        <span class="n">set_features</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="n">set_labels</span> <span class="o">=</span> <span class="p">{}</span>
        <span class="k">for</span> <span class="n">set_name</span><span class="p">,</span> <span class="n">is_set</span> <span class="ow">in</span> <span class="n">is_set_dict</span><span class="p">.</span><span class="nf">items</span><span class="p">():</span>
            <span class="n">set_features</span><span class="p">[</span><span class="n">set_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">train_features</span><span class="p">[</span><span class="n">is_set</span><span class="p">,</span> <span class="p">:]</span>
            <span class="n">set_labels</span><span class="p">[</span><span class="n">set_name</span><span class="p">]</span> <span class="o">=</span> <span class="n">train_labels</span><span class="p">[</span><span class="n">is_set</span><span class="p">]</span>
        
        <span class="n">min_validation_loss</span> <span class="o">=</span> <span class="bp">None</span>        
        <span class="k">for</span> <span class="n">max_epochs_index</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">self</span><span class="p">.</span><span class="n">max_epochs</span><span class="p">):</span>
            <span class="n">learner</span> <span class="o">=</span> <span class="nc">TorchLearner</span><span class="p">(</span>
                <span class="n">max_epochs</span><span class="o">=</span><span class="n">max_epochs_index</span><span class="p">,</span>
                <span class="n">batch_size</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">batch_size</span><span class="p">,</span>
                <span class="n">step_size</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">step_size</span><span class="p">,</span>
                <span class="n">units_per_layer</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">units_per_layer</span><span class="p">)</span>
            <span class="n">learner</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">set_features</span><span class="p">,</span> <span class="n">set_labels</span><span class="p">)</span>
            <span class="n">loss_df</span> <span class="o">=</span> <span class="n">learner</span><span class="p">.</span><span class="n">loss_df</span>
            <span class="n">validation_loss_df</span> <span class="o">=</span> <span class="n">loss_df</span><span class="p">[</span><span class="n">loss_df</span><span class="p">[</span><span class="sh">"</span><span class="s">set_name</span><span class="sh">"</span><span class="p">]</span> <span class="o">==</span> <span class="sh">"</span><span class="s">validation</span><span class="sh">"</span><span class="p">]</span>
            <span class="n">validation_loss</span> <span class="o">=</span> <span class="n">validation_loss_df</span><span class="p">[</span><span class="sh">"</span><span class="s">loss</span><span class="sh">"</span><span class="p">].</span><span class="nf">min</span><span class="p">()</span>
            <span class="k">if</span> <span class="n">min_validation_loss</span> <span class="ow">is</span> <span class="bp">None</span> <span class="ow">or</span> <span class="n">validation_loss</span> <span class="o">&lt;=</span> <span class="n">min_validation_loss</span><span class="p">:</span>
                <span class="n">min_validation_loss</span> <span class="o">=</span> <span class="n">validation_loss</span>
                <span class="n">self</span><span class="p">.</span><span class="n">best_max_epochs</span> <span class="o">=</span> <span class="n">max_epochs_index</span>
            <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">epoch = </span><span class="si">{</span><span class="n">max_epochs_index</span><span class="si">}</span><span class="s">, min_val_loss = </span><span class="si">{</span><span class="n">min_validation_loss</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>
             
        <span class="n">self</span><span class="p">.</span><span class="n">torch_learner</span> <span class="o">=</span> <span class="nc">TorchLearner</span><span class="p">(</span>
            <span class="n">max_epochs</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">best_max_epochs</span><span class="p">,</span>
            <span class="n">batch_size</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">batch_size</span><span class="p">,</span>
            <span class="n">step_size</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">step_size</span><span class="p">,</span>
            <span class="n">units_per_layer</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">units_per_layer</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">torch_learner</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">set_features</span><span class="p">,</span> <span class="n">set_labels</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">loss_df</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="n">torch_learner</span><span class="p">.</span><span class="n">loss_df</span>
        <span class="nf">print</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">best_max_epochs: </span><span class="si">{</span><span class="n">self</span><span class="p">.</span><span class="n">best_max_epochs</span><span class="si">}</span><span class="sh">"</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">decision_function</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="n">torch_learner</span><span class="p">.</span><span class="nf">decision_function</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="n">torch_learner</span><span class="p">.</span><span class="nf">predict</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</code></pre></div></div> <h3 id="torch-model-definition">Torch Model Definition</h3> <p>Defines the structure of the neural network.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">TorchModel</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="o">*</span><span class="n">units_per_layer</span><span class="p">):</span>
        <span class="nf">super</span><span class="p">().</span><span class="nf">__init__</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">flatten</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Flatten</span><span class="p">()</span>
        <span class="n">seq_args</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">layer_i</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">units_per_layer</span><span class="p">)</span><span class="o">-</span><span class="mi">1</span><span class="p">):</span>
            <span class="n">units_in</span> <span class="o">=</span> <span class="n">units_per_layer</span><span class="p">[</span><span class="n">layer_i</span><span class="p">]</span>
            <span class="n">units_out</span> <span class="o">=</span> <span class="n">units_per_layer</span><span class="p">[</span><span class="n">layer_i</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span>
            <span class="n">seq_args</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Linear</span><span class="p">(</span><span class="n">units_in</span><span class="p">,</span> <span class="n">units_out</span><span class="p">))</span>
            <span class="k">if</span> <span class="n">layer_i</span> <span class="o">!=</span> <span class="nf">len</span><span class="p">(</span><span class="n">units_per_layer</span><span class="p">)</span><span class="o">-</span><span class="mi">2</span><span class="p">:</span>
                <span class="n">seq_args</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">ReLU</span><span class="p">())</span>     
        <span class="n">self</span><span class="p">.</span><span class="n">linear_relu_stack</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">Sequential</span><span class="p">(</span><span class="o">*</span><span class="n">seq_args</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="n">X</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">flatten</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="nf">linear_relu_stack</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
</code></pre></div></div> <h3 id="torch-learner-class">Torch Learner Class</h3> <p>Handles the training process for the neural network.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">class</span> <span class="nc">TorchLearner</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">max_epochs</span><span class="p">,</span> <span class="n">batch_size</span><span class="p">,</span> <span class="n">step_size</span><span class="p">,</span> <span class="n">units_per_layer</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">max_epochs</span> <span class="o">=</span> <span class="n">max_epochs</span>
        <span class="n">self</span><span class="p">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="n">batch_size</span>
        <span class="n">self</span><span class="p">.</span><span class="n">step_size</span> <span class="o">=</span> <span class="n">step_size</span>
        <span class="n">self</span><span class="p">.</span><span class="n">units_per_layer</span> <span class="o">=</span> <span class="n">units_per_layer</span>
        <span class="n">self</span><span class="p">.</span><span class="n">model</span> <span class="o">=</span> <span class="nc">TorchModel</span><span class="p">(</span><span class="o">*</span><span class="n">self</span><span class="p">.</span><span class="n">units_per_layer</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">loss_fun</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">nn</span><span class="p">.</span><span class="nc">BCEWithLogitsLoss</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">optimizer</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">optim</span><span class="p">.</span><span class="nc">SGD</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="nf">parameters</span><span class="p">(),</span> <span class="n">lr</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">step_size</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">take_step</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="n">loss_tensor</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">calc_loss_tensor</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="n">self</span><span class="p">.</span><span class="n">optimizer</span><span class="p">.</span><span class="nf">zero_grad</span><span class="p">()</span>
        <span class="n">loss_tensor</span><span class="p">.</span><span class="nf">backward</span><span class="p">()</span>
        <span class="n">self</span><span class="p">.</span><span class="n">optimizer</span><span class="p">.</span><span class="nf">step</span><span class="p">()</span>
        <span class="k">return</span> <span class="n">loss_tensor</span><span class="p">.</span><span class="nf">item</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">calc_loss_tensor</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="n">X_features</span> <span class="o">=</span> <span class="n">X</span><span class="p">.</span><span class="nf">float</span><span class="p">()</span>
        <span class="n">y_labels</span> <span class="o">=</span> <span class="n">y</span><span class="p">.</span><span class="nf">float</span><span class="p">()</span>
        <span class="n">pred_tensor</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">model</span><span class="p">(</span><span class="n">X_features</span><span class="p">).</span><span class="nf">reshape</span><span class="p">(</span><span class="nf">len</span><span class="p">(</span><span class="n">y_labels</span><span class="p">))</span>
        <span class="n">loss_tensor</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">loss_fun</span><span class="p">(</span><span class="n">pred_tensor</span><span class="p">,</span> <span class="n">y_labels</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">loss_tensor</span>

    <span class="k">def</span> <span class="nf">fit</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="n">set_features</span> <span class="o">=</span> <span class="n">X</span>
        <span class="n">set_labels</span> <span class="o">=</span> <span class="n">y</span>        
        <span class="n">subtrain_csv</span> <span class="o">=</span> <span class="nc">CSV</span><span class="p">(</span><span class="n">set_features</span><span class="p">[</span><span class="sh">"</span><span class="s">subtrain</span><span class="sh">"</span><span class="p">],</span> <span class="n">set_labels</span><span class="p">[</span><span class="sh">"</span><span class="s">subtrain</span><span class="sh">"</span><span class="p">])</span>
        <span class="n">subtrain_dl</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="nc">DataLoader</span><span class="p">(</span><span class="n">subtrain_csv</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        <span class="n">validation_csv</span> <span class="o">=</span> <span class="nc">CSV</span><span class="p">(</span><span class="n">set_features</span><span class="p">[</span><span class="sh">"</span><span class="s">validation</span><span class="sh">"</span><span class="p">],</span> <span class="n">set_labels</span><span class="p">[</span><span class="sh">"</span><span class="s">validation</span><span class="sh">"</span><span class="p">])</span>
        <span class="n">validation_dl</span> <span class="o">=</span> <span class="n">torch</span><span class="p">.</span><span class="n">utils</span><span class="p">.</span><span class="n">data</span><span class="p">.</span><span class="nc">DataLoader</span><span class="p">(</span><span class="n">validation_csv</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">self</span><span class="p">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
        
        <span class="n">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="nf">train</span><span class="p">()</span>
        <span class="n">loss_df_list</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">epoch</span> <span class="ow">in</span> <span class="nf">range</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="n">max_epochs</span><span class="p">):</span>
            <span class="n">total_subtrain_loss</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">total_validation_loss</span> <span class="o">=</span> <span class="mi">0</span>
            <span class="n">n_subtrain_batches</span> <span class="o">=</span> <span class="nf">len</span><span class="p">(</span><span class="n">subtrain_dl</span><span class="p">)</span>
            <span class="n">n_validation_batches</span> <span class="o">=</span> <span class="nf">len</span><span class="p">(</span><span class="n">validation_dl</span><span class="p">)</span>
            <span class="k">for</span> <span class="n">batch_features</span><span class="p">,</span> <span class="n">batch_labels</span> <span class="ow">in</span> <span class="n">subtrain_dl</span><span class="p">:</span>
                <span class="n">subtrain_loss_item</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">take_step</span><span class="p">(</span><span class="n">batch_features</span><span class="p">,</span> <span class="n">batch_labels</span><span class="p">)</span>
                <span class="n">total_subtrain_loss</span> <span class="o">+=</span> <span class="n">subtrain_loss_item</span>

            <span class="k">for</span> <span class="n">batch_features</span><span class="p">,</span> <span class="n">batch_labels</span> <span class="ow">in</span> <span class="n">validation_dl</span><span class="p">:</span>
                <span class="n">validation_loss_item</span> <span class="o">=</span> <span class="n">self</span><span class="p">.</span><span class="nf">calc_loss_tensor</span><span class="p">(</span><span class="n">batch_features</span><span class="p">,</span> <span class="n">batch_labels</span><span class="p">).</span><span class="nf">item</span><span class="p">()</span>
                <span class="n">total_validation_loss</span> <span class="o">+=</span> <span class="n">validation_loss_item</span>

            <span class="n">avg_subtrain_loss</span> <span class="o">=</span> <span class="n">total_subtrain_loss</span> <span class="o">/</span> <span class="n">n_subtrain_batches</span>
            <span class="n">loss_df_list</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">({</span>
                <span class="sh">"</span><span class="s">set_name</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">subtrain</span><span class="sh">"</span><span class="p">,</span>
                <span class="sh">"</span><span class="s">loss</span><span class="sh">"</span><span class="p">:</span> <span class="n">avg_subtrain_loss</span><span class="p">,</span>
                <span class="sh">"</span><span class="s">epoch</span><span class="sh">"</span><span class="p">:</span> <span class="n">epoch</span><span class="p">,</span>
            <span class="p">},</span> <span class="n">index</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>
            
            <span class="n">avg_validation_loss</span> <span class="o">=</span> <span class="n">total_validation_loss</span> <span class="o">/</span> <span class="n">n_validation_batches</span>
            <span class="n">loss_df_list</span><span class="p">.</span><span class="nf">append</span><span class="p">(</span><span class="n">pd</span><span class="p">.</span><span class="nc">DataFrame</span><span class="p">({</span>
                <span class="sh">"</span><span class="s">set_name</span><span class="sh">"</span><span class="p">:</span> <span class="sh">"</span><span class="s">validation</span><span class="sh">"</span><span class="p">,</span>
                <span class="sh">"</span><span class="s">loss</span><span class="sh">"</span><span class="p">:</span> <span class="n">avg_validation_loss</span><span class="p">,</span>
                <span class="sh">"</span><span class="s">epoch</span><span class="sh">"</span><span class="p">:</span> <span class="n">epoch</span><span class="p">,</span>
            <span class="p">},</span> <span class="n">index</span><span class="o">=</span><span class="p">[</span><span class="mi">0</span><span class="p">]))</span>

        <span class="n">self</span><span class="p">.</span><span class="n">loss_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">concat</span><span class="p">(</span><span class="n">loss_df_list</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">decision_function</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="n">self</span><span class="p">.</span><span class="n">model</span><span class="p">.</span><span class="nf">eval</span><span class="p">()</span>
        <span class="k">with</span> <span class="n">torch</span><span class="p">.</span><span class="nf">no_grad</span><span class="p">():</span>
            <span class="k">return</span> <span class="n">self</span><span class="p">.</span><span class="nf">model</span><span class="p">(</span><span class="n">torch</span><span class="p">.</span><span class="nc">Tensor</span><span class="p">(</span><span class="n">X</span><span class="p">)).</span><span class="nf">numpy</span><span class="p">().</span><span class="nf">ravel</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">predict</span><span class="p">(</span><span class="n">self</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">np</span><span class="p">.</span><span class="nf">where</span><span class="p">(</span><span class="n">self</span><span class="p">.</span><span class="nf">decision_function</span><span class="p">(</span><span class="n">X</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">)</span>
</code></pre></div></div> <h2 id="data-preparation">Data Preparation</h2> <p>Load and preprocess the spam and zip datasets.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">spam_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="sh">"</span><span class="s">./data/spam.data</span><span class="sh">"</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="sh">"</span><span class="s"> </span><span class="sh">"</span><span class="p">)</span>
<span class="n">spam_features</span> <span class="o">=</span> <span class="n">spam_df</span><span class="p">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="p">:</span><span class="o">-</span><span class="mi">1</span><span class="p">].</span><span class="nf">to_numpy</span><span class="p">()</span>
<span class="n">spam_labels</span> <span class="o">=</span> <span class="n">spam_df</span><span class="p">.</span><span class="n">iloc</span><span class="p">[:,</span> <span class="o">-</span><span class="mi">1</span><span class="p">].</span><span class="nf">to_numpy</span><span class="p">()</span>

<span class="n">spam_mean</span> <span class="o">=</span> <span class="n">spam_features</span><span class="p">.</span><span class="nf">mean</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">spam_sd</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="nf">sqrt</span><span class="p">(</span><span class="n">spam_features</span><span class="p">.</span><span class="nf">var</span><span class="p">(</span><span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">))</span>
<span class="n">spam_scaled_features</span> <span class="o">=</span> <span class="p">(</span><span class="n">spam_features</span> <span class="o">-</span> <span class="n">spam_mean</span><span class="p">)</span> <span class="o">/</span> <span class="n">spam_sd</span>

<span class="n">zip_df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="nf">read_csv</span><span class="p">(</span><span class="sh">"</span><span class="s">./data/zip.test.gz</span><span class="sh">"</span><span class="p">,</span> <span class="n">header</span><span class="o">=</span><span class="bp">None</span><span class="p">,</span> <span class="n">sep</span><span class="o">=</span><span class="sh">"</span><span class="s"> </span><span class="sh">"</span><span class="p">)</span>
<span class="n">is01</span> <span class="o">=</span> <span class="n">zip_df</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">isin</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">])</span>
<span class="n">zip01_df</span> <span class="o">=</span> <span class="n">zip_df</span><span class="p">.</span><span class="n">loc</span><span class="p">[</span><span class="n">is01</span><span class="p">,</span> <span class="p">:]</span>
<span class="n">zip_features</span> <span class="o">=</span> <span class="n">zip01_df</span><span class="p">.</span><span class="n">loc</span><span class="p">[:,</span> <span class="mi">1</span><span class="p">:].</span><span class="nf">to_numpy</span><span class="p">()</span>
<span class="n">zip_labels</span> <span class="o">=</span> <span class="n">zip01_df</span><span class="p">[</span><span class="mi">0</span><span class="p">].</span><span class="nf">to_numpy</span><span class="p">()</span>

<span class="n">data_dict</span> <span class="o">=</span> <span class="p">{</span>
    <span class="sh">"</span><span class="s">zip</span><span class="sh">"</span><span class="p">:</span> <span class="p">(</span><span class="n">zip_features</span><span class="p">,</span> <span class="n">zip_labels</span><span class="p">),</span>
    <span class="sh">"</span><span class="s">spam</span><span class="sh">"</span><span class="p">:</span> <span class="p">(</span><span class="n">spam_scaled_features</span><span class="p">,</span> <span class="n">spam_labels</span><span class="p">),</span>
<span class="p">}</span>
</code></pre></div></div> <h2 id="hyperparameter-training-and-diagnostic-plot">Hyperparameter Training and Diagnostic Plot</h2> <p>Generate diagnostic plots for model performance.</p> <div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">hyperparameter_training_and_diagnostic_plot</span><span class="p">():</span>
    <span class="k">for</span> <span class="n">data_set</span><span class="p">,</span> <span class="p">(</span><span class="n">input_mat</span><span class="p">,</span> <span class="n">output_vec</span><span class="p">)</span> <span class="ow">in</span> <span class="n">data_dict</span><span class="p">.</span><span class="nf">items</span><span class="p">():</span>
        <span class="n">ncol</span> <span class="o">=</span> <span class="n">input_mat</span><span class="p">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>
        <span class="n">sizes_dict</span> <span class="o">=</span> <span class="p">{</span>
            <span class="sh">"</span><span class="s">linear</span><span class="sh">"</span><span class="p">:</span> <span class="p">(</span><span class="n">ncol</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
            <span class="sh">"</span><span class="s">nnet</span><span class="sh">"</span><span class="p">:</span> <span class="p">(</span><span class="n">ncol</span><span class="p">,</span> <span class="mi">100</span><span class="p">,</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span>
        <span class="p">}</span>
        <span class="k">for</span> <span class="n">model_name</span><span class="p">,</span> <span class="n">units_per_layer</span> <span class="ow">in</span> <span class="n">sizes_dict</span><span class="p">.</span><span class="nf">items</span><span class="p">():</span>
            <span class="n">my_nn_cv</span> <span class="o">=</span> <span class="nc">TorchLearnerCV</span><span class="p">(</span>
                <span class="n">max_epochs</span><span class="o">=</span><span class="mi">40</span><span class="p">,</span>
                <span class="n">batch_size</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span>
                <span class="n">step_size</span><span class="o">=</span><span class="mf">0.01</span><span class="p">,</span>
                <span class="n">units_per_layer</span><span class="o">=</span><span class="n">units_per_layer</span><span class="p">)</span>
            <span class="n">my_nn_cv</span><span class="p">.</span><span class="nf">fit</span><span class="p">(</span><span class="n">input_mat</span><span class="p">,</span> <span class="n">output_vec</span><span class="p">)</span>
            <span class="n">test_loss_df</span> <span class="o">=</span> <span class="n">my_nn_cv</span><span class="p">.</span><span class="n">loss_df</span>
            <span class="n">gg</span> <span class="o">=</span> <span class="n">p9</span><span class="p">.</span><span class="nf">ggplot</span><span class="p">(</span><span class="n">data</span><span class="o">=</span><span class="n">test_loss_df</span><span class="p">)</span> <span class="o">+</span>\
                <span class="n">p9</span><span class="p">.</span><span class="nf">aes</span><span class="p">(</span><span class="n">x</span><span class="o">=</span><span class="sh">"</span><span class="s">epoch</span><span class="sh">"</span><span class="p">,</span> <span class="n">y</span><span class="o">=</span><span class="sh">"</span><span class="s">loss</span><span class="sh">"</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="sh">"</span><span class="s">set_name</span><span class="sh">"</span><span class="p">)</span> <span class="o">+</span>\
                <span class="n">p9</span><span class="p">.</span><span class="nf">geom_line</span><span class="p">()</span> <span class="o">+</span>\
                <span class="n">p9</span><span class="p">.</span><span class="nf">scale_color_discrete</span><span class="p">(</span><span class="n">name</span><span class="o">=</span><span class="sh">"</span><span class="s">set_name</span><span class="sh">"</span><span class="p">)</span> <span class="o">+</span>\
                <span class="n">p9</span><span class="p">.</span><span class="nf">labs</span><span class="p">(</span><span class="n">title</span><span class="o">=</span><span class="sa">f</span><span class="sh">"</span><span class="s">Loss for </span><span class="si">{</span><span class="n">data_set</span><span class="si">}</span><span class="s"> dataset, </span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s"> model</span><span class="sh">"</span><span class="p">)</span>
            <span class="n">gg</span><span class="p">.</span><span class="nf">save</span><span class="p">(</span><span class="sa">f</span><span class="sh">"</span><span class="s">./06_torch_mlp/</span><span class="si">{</span><span class="n">data_set</span><span class="si">}</span><span class="s">_</span><span class="si">{</span><span class="n">model_name</span><span class="si">}</span><span class="s">.png</span><span class="sh">"</span><span class="p">)</span>
</code></pre></div></div> <div class="row justify-content-sm-center"> <div class="col-sm-8 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/p7_spam_linear-480.webp 480w,/assets/img/p7_spam_linear-800.webp 800w,/assets/img/p7_spam_linear-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/p7_spam_linear.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="p7_spam_linear" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm-4 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/p7_spam_nnet-480.webp 480w,/assets/img/p7_spam_nnet-800.webp 800w,/assets/img/p7_spam_nnet-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/p7_spam_nnet.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="p7_spam_nnet" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="row justify-content-sm-center"> <div class="col-sm-8 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/p7_zip_linear-480.webp 480w,/assets/img/p7_zip_linear-800.webp 800w,/assets/img/p7_zip_linear-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/p7_zip_linear.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="p7_zip_linear" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> <div class="col-sm-4 mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/p7_zip_nnet-480.webp 480w,/assets/img/p7_zip_nnet-800.webp 800w,/assets/img/p7_zip_nnet-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/p7_zip_nnet.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" title="p7_zip_nnet" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> ## Experiments and Application Run experiments and evaluate model performance. ```python def experiments_and_application(): test_acc_df_list = [] for data_set, (input_mat, output_vec) in data_dict.items(): k_fold = KFold(n_splits=3, shuffle=True, random_state=1) for fold_id, indices in enumerate(k_fold.split(input_mat)): index_dict = dict(zip(["train", "test"], indices)) param_dicts = [{'n_neighbors': [x]} for x in range(1, 21)] set_data_dict = {} for set_name, index_vec in index_dict.items(): set_data_dict[set_name] = { "X": input_mat[index_vec], "y": output_vec[index_vec] } sizes_dict = { "linear": (input_mat.shape[1], 1), "deep": (input_mat.shape[1], 100, 10, 1) } predict_dict = {} for model_name, units_per_layer in sizes_dict.items(): my_nn_cv = TorchLearnerCV( max_epochs=40, batch_size=5, step_size=0.01, units_per_layer=units_per_layer) my_nn_cv.fit(**set_data_dict["train"]) predict_dict[model_name] = my_nn_cv.predict(set_data_dict["test"]['X']) pipe = make_pipeline( StandardScaler(), LogisticRegression(max_iter=1000)) pipe.fit(**set_data_dict["train"]) grid_search_cv = make_pipeline(StandardScaler(), GridSearchCV(estimator=KNeighborsClassifier(), param_grid=param_dicts, cv=5)) grid_search_cv.fit(**set_data_dict["train"]) featureless = Featureless() featureless.fit(set_data_dict["train"]['y']) test_data_x = set_data_dict["test"]['X'] test_data_y = set_data_dict["test"]['y'] pred_dict = { "LogisticRegressionCV": pipe.predict(test_data_x), "featureless": featureless.predict(test_data_x), "GridSearchCV+KNNC": grid_search_cv.predict(test_data_x), "TorchLearnerCV+Linear": predict_dict["linear"], "TorchLearnerCV+Deep": predict_dict["deep"] } for algorithm, pred_vec in pred_dict.items(): test_acc_dict = { "test_accuracy_percent": (pred_vec == test_data_y).mean() * 100, "data_set": data_set, "fold_id": fold_id, "algorithm": algorithm } test_acc_df_list.append(pd.DataFrame(test_acc_dict, index=[0])) test_acc_df = pd.concat(test_acc_df_list) print(test_acc_df) gg = p9.ggplot() +\ p9.geom_point( p9.aes( x="test_accuracy_percent", y="algorithm" ), data=test_acc_df) +\ p9.facet_wrap("data_set") gg.save("./accuracy_facetted.png") ``` <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/p7_accuracy_facetted-480.webp 480w,/assets/img/p7_accuracy_facetted-800.webp 800w,/assets/img/p7_accuracy_facetted-1400.webp 1400w," sizes="95vw" type="image/webp"></source> <img src="/assets/img/p7_accuracy_facetted.png" class="img-fluid rounded z-depth-1" width="600px" height="600px" title="threshold_network_full" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> # Interpretation of Test Accuracy Results The graph above shows the test accuracy percentages for different algorithms applied to two datasets: `spam` and `zip`. Each point represents the accuracy of a particular algorithm for a specific fold of cross-validation. The algorithms compared include a featureless model, linear and deep neural networks trained with cross-validation, logistic regression with cross-validation, and k-nearest neighbors with hyperparameter tuning using grid search. ## Key Observations ### Spam Dataset - **Featureless Model**: The accuracy is consistently around 60%, indicating that the most frequent class constitutes 60% of the dataset. This serves as a baseline. - **TorchLearnerCV+Linear**: The accuracy is significantly higher, around 90%, demonstrating that a simple neural network with a linear configuration performs well on the spam dataset. - **TorchLearnerCV+Deep**: Similar to the linear model, the deep neural network achieves around 90% accuracy, suggesting that additional complexity does not significantly improve performance for this dataset. - **LogisticRegressionCV**: Achieves close to 90% accuracy, indicating that logistic regression is quite effective for the spam dataset. - **GridSearchCV+KNNC**: Also achieves close to 90% accuracy, showing that k-nearest neighbors with optimal hyperparameters can perform well on this dataset. ### Zip Dataset - **Featureless Model**: The accuracy is around 65%, indicating the baseline performance for the zip dataset. - **TorchLearnerCV+Linear**: The accuracy is around 85%, showing that a simple linear neural network configuration is effective but leaves room for improvement. - **TorchLearnerCV+Deep**: Achieves nearly 100% accuracy, indicating that a deep neural network is highly effective for the zip dataset, likely capturing complex patterns in the data. - **LogisticRegressionCV**: Accuracy is around 90%, showing that logistic regression is also quite effective for the zip dataset but slightly less so than the deep neural network. - **GridSearchCV+KNNC**: The accuracy is around 95%, indicating that k-nearest neighbors with optimal hyperparameters perform very well on this dataset. ## Conclusion - For the **spam dataset**, both simple and complex models (linear and deep neural networks, logistic regression, and k-nearest neighbors) perform similarly well, with accuracies around 90%. - For the **zip dataset**, the deep neural network outperforms all other models, achieving near-perfect accuracy. Other models, including logistic regression and k-nearest neighbors, also perform well but slightly less so. This analysis highlights the importance of model selection and hyperparameter tuning tailored to the specific characteristics of each dataset. Complex models like deep neural networks can capture more intricate patterns, leading to better performance in datasets with higher complexity. </div> </article> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Daniel Agyapong. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?b7816bd189846d29eded8745f9c4cf77"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.min.js"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>